# Отчёт по сравнению моделей бинарной классификации токсичных сообщений

Сравнение четырёх реализованных моделей по основным метрикам качества (**accuracy**, **precision**, **recall**, **f1-score**) на отложенном eval-наборе данных.

Модели:
1. **Логистическая регрессия (Logistic Regression)**
2. **Случайный лес (Random Forest)**
3. **RoBERTa**
4. **CodeBERT**

---

## 1. Результаты оценки

| Модель              | Accuracy | Precision | Recall | F1-score |
|----------------------|-----------|------------|---------|-----------|
| Logistic Regression  | 0.8924 ± 0.0090 | 0.6990 ± 0.0249 | 0.7918 ± 0.0273 | 0.7421 ± 0.0203 |
| Random Forest        | 0.9117 ± 0.0073 | 0.8623 ± 0.0218 | 0.6527 ± 0.0281 | 0.7427 ± 0.0237 |
| RoBERTa              | 0.9151 | 0.7914 | 0.7679 | 0.7795 |
| CodeBERT             | 0.9078 | 0.7418 | 0.8095 | 0.7742 |

---

## 2. Анализ результатов

- **Логистическая регрессия** показала достаточно сбалансированные значения recall и f1, однако по точности (accuracy) уступает более сложным моделям.
- **Случайный лес** продемонстрировал наилучшую точность (accuracy ≈ 0.91) и высокую precision, но заметно проигрывает по recall, что говорит о склонности к пропуску токсичных сообщений.
- **RoBERTa** достигла лучшего баланса между всеми метриками, особенно по совокупности `precision` и `recall`, что дало максимальное значение **F1 = 0.7795**.
- **CodeBERT** показал близкие результаты к RoBERTa (немного выше recall, но чуть ниже precision), при этом итоговое качество схоже по F1.

---

## 3. Вывод

По итогам экспериментов:
- **Наилучший общий баланс метрик - у модели RoBERTa.**
- **CodeBERT** лишь незначительно уступает RoBERTa и также может считаться подходящей моделью.
- Классические модели (логистическая регрессия и случайный лес) показали хорошие результаты при существенно меньших ресурсных затратах, однако уступают трансформерам в способности улавливать контекст и семантику текста.

**Итоговый рейтинг по F1-score:**
1. RoBERTa - 0.7795  
2. CodeBERT - 0.7742  
3. Random Forest - 0.7427  
4. Logistic Regression - 0.7421
