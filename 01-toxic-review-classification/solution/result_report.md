# Отчёт по сравнению моделей бинарной классификации токсичных сообщений

Сравнение четырёх реализованных моделей по основным метрикам качества (**accuracy**, **precision**, **recall**, **f1-score**) на отложенном eval-наборе данных.

Модели:
1. **Логистическая регрессия (Logistic Regression)**
2. **Случайный лес (Random Forest)**
3. **RoBERTa**
4. **CodeBERT**

---

## 1. Результаты оценки

| Модель              | Accuracy | Precision     | Recall | F1-score |
|----------------------|-----------|---------------|---------|-----------|
| Logistic Regression  | 0.8954 ± 0.0091 | 0.7070 ± 0.0237 | 0.7950 ± 0.0293 | 0.7481 ± 0.0216 |
| Random Forest        | 0.9114 ± 0.0076 | 0.8619 ± 0.0217 | 0.6511 ± 0.0303 | 0.7415 ± 0.0252 |
| RoBERTa              | 0.9178 | 0.793         | 0.7837 | 0.7884 |
| CodeBERT             | 0.9163 | 0.788         | 0.7817 | 0.7848 |

---

## 2. Анализ результатов

- **Логистическая регрессия** показала достаточно сбалансированные значения recall и f1, однако по точности (accuracy) уступает более сложным моделям.
- **Случайный лес** продемонстрировал наилучшую точность (precision ≈ 0.86), но заметно проигрывает по recall, что говорит о склонности к пропуску токсичных сообщений.
- **RoBERTa** достигла лучшего баланса между всеми метриками, особенно по совокупности `precision` и `recall`, что дало максимальное значение **F1 = 0.7848**.
- **CodeBERT** показал близкие результаты к RoBERTa (немного выше recall, но чуть ниже precision), при этом итоговое качество схоже по F1.

---

## 3. Вывод

По итогам экспериментов:
- **Наилучший общий баланс метрик - у модели RoBERTa.**
- **CodeBERT** лишь незначительно уступает RoBERTa и также может считаться подходящей моделью.
- Классические модели (логистическая регрессия и случайный лес) показали хорошие результаты при существенно меньших ресурсных затратах, однако уступают трансформерам в способности улавливать контекст и семантику текста.

**Итоговый рейтинг по F1-score:**
1. RoBERTa - 0.7884  
2. CodeBERT - 0.7848 
3. Random Forest - 0.7415
4. Logistic Regression - 0.7481
